"""Generate structured summaries from earnings call transcripts using OpenAI."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional

from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables from .env file if it exists
load_dotenv()


@dataclass
class TranscriptSummary:
    """Container for a synthesized earnings call summary.

    Attributes:
        company: Name of the company covered in the transcript.
        transcript_path: Path to the transcript file that was summarized.
        summary_text: Human-readable summary generated by the language model.
    """

    company: str
    transcript_path: Path
    summary_text: str


SYSTEM_PROMPT = """You are a research analyst reviewing earnings call transcripts for potential competitors in consumer lending.
You distill dense, noisy transcripts into concise, actionable insights for a product and strategy team.
Keep your writing direct, factual, and bullet-heavy. Avoid generic corporate language.
"""


def _build_user_prompt(company: str, transcript: str) -> str:
    """Create the instruction prompt for the model.

    The prompt asks for a competitor-focused readout that captures:
    * Economic performance and revenue/expense trends.
    * Credit performance and underwriting details (losses, delinquencies, reserves).
    * Commentary on macro conditions and consumer health.
    * New products, partnerships, and channel/tech updates.
    * Any cutting-edge ideas or signals that warrant extra attention.
    * Brief risks and watch-outs.
    """

    transcript_block = transcript.strip()
    return (
        f"You are reviewing the {company} earnings call transcript.\n"
        "Summarize for a consumer lending competitor who wants tactical takeaways.\n"
        "Use short paragraphs and bullet lists with section headers. Be explicit about metrics and directionality when provided.\n\n"
        "Required sections:\n"
        "1) Economic performance\n"
        "2) Credit performance\n"
        "3) Macro & consumer health\n"
        "4) New products, partnerships, or technology\n"
        "5) Cutting-edge or noteworthy items (flag anything experimental or differentiating)\n"
        "6) Risks & watch-outs\n\n"
        f"Transcript:\n\"\"\"{transcript_block}\"\"\"\n"
    )


def synthesize_transcript(
    transcript_path: Path | str,
    *,
    company: str,
    model: str = "gpt-4o-mini",
    client: Optional[OpenAI] = None,
    max_output_tokens: int = 800,
    extra_instructions: Optional[Iterable[str]] = None,
    transcript_text_override: Optional[str] = None,
) -> TranscriptSummary:
    """Read a transcript file and return a synthesized summary.

    Args:
        transcript_path: Path to the plain-text earnings call transcript.
        company: Name of the company whose transcript is being summarized.
        model: OpenAI chat model identifier to use.
        client: Optional shared OpenAI client. If not provided, a new client is created
            using environment configuration.
        max_output_tokens: Upper bound for tokens in the generated summary.
        extra_instructions: Optional list of bullet instructions appended to the
            system message for caller-specific guidance.
        transcript_text_override: Raw transcript content to use instead of reading from disk.

    Returns:
        TranscriptSummary containing the synthesized content.
    """

    path = Path(transcript_path)
    if not transcript_text_override and not path.exists():
        raise FileNotFoundError(f"Transcript file not found: {path}")

    transcript = transcript_text_override or path.read_text(encoding="utf-8")
    if not transcript.strip():
        raise ValueError("Transcript content is empty; provide text to summarize.")

    guidance_lines = list(extra_instructions or [])
    guidance = "\n".join(f"- {line}" for line in guidance_lines)
    system_prompt = SYSTEM_PROMPT + (f"\nCaller notes:\n{guidance}" if guidance else "")

    message = _build_user_prompt(company, transcript)

    api_client = client or OpenAI()
    response = api_client.chat.completions.create(
        model=model,
        temperature=0.2,
        max_tokens=max_output_tokens,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message},
        ],
    )

    summary_text = response.choices[0].message.content or ""

    return TranscriptSummary(company=company, transcript_path=path, summary_text=summary_text)


def summarize_text(
    transcript: str,
    *,
    company: str,
    model: str = "gpt-4o-mini",
    client: Optional[OpenAI] = None,
    max_output_tokens: int = 800,
    extra_instructions: Optional[Iterable[str]] = None,
) -> str:
    """Summarize a transcript string without reading from disk.

    Returns only the summary text and is useful for testing.
    """

    summary = synthesize_transcript(
        Path("in-memory-transcript.txt"),
        company=company,
        model=model,
        client=client,
        max_output_tokens=max_output_tokens,
        extra_instructions=extra_instructions,
        transcript_text_override=transcript,
    )
    return summary.summary_text
