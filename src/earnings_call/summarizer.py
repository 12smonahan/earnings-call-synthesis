"""Generate structured summaries from earnings call transcripts using OpenAI."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional

from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables from .env file if it exists
load_dotenv()


@dataclass
class TranscriptSummary:
    """Container for a synthesized earnings call summary.

    Attributes:
        company: Name of the company covered in the transcript.
        transcript_path: Path to the transcript file that was summarized.
        summary_text: Human-readable summary generated by the language model.
    """

    company: str
    transcript_path: Path
    summary_text: str


SYSTEM_PROMPT = """You are a chief executive at a consumer lending competitor dissecting an earnings call transcript.
Your goal is to extract granular signals that inform strategy, product bets, and competitive positioning.
Write with the urgency and specificity of a CEO preparing a counter-move playbook. Avoid corporate euphemisms; favor concrete, quotable facts.
Pay particular attention to details that may indicate changing health of the US consumer, the trajectory of this companay, and any key competitive intelligence (underwriting changes, new product features, etc.)
"""


def _build_user_prompt(company: str, transcript: str) -> str:
    """Create the instruction prompt for the model.

    The prompt asks for a competitor-focused readout that captures:
    * Economic performance and revenue/expense trends.
    * Credit performance and underwriting details (losses, delinquencies, reserves).
    * Commentary on macro conditions and consumer health.
    * New products, partnerships, and channel/tech updates.
    * Any cutting-edge ideas or signals that warrant extra attention.
    * Brief risks and watch-outs.
    """

    transcript_block = transcript.strip()
    return (
        f"You are reviewing the {company} earnings call transcript.\n"
        "Summarize for a consumer lending competitor CEO preparing a counter-strategy.\n"
        "Deliver 2,500-3,000 words total with a ~350 word executive summary followed by multi-paragraph deep dives for every section.\n"
        "Use explicit metrics (levels and directionality), cite product names, and call out signals that demand a response.\n"
        "Keep prose direct and decisive, but format as plain text (no Markdown or bullet symbols).\n"
        "For readability in email, use uppercase section headers, short paragraphs, and divider lines made of '=' characters between major sections.\n"
        "Do not truncate sectionsâ€”ensure each requested area is fully covered even if the response is lengthy, and keep writing until every deep dive is complete.\n\n"
        "Required structure:\n"
        "1) EXECUTIVE SUMMARY (~300 words focused on competitive implications)\n"
        "2) ECONOMIC PERFORMANCE\n"
        "3) CREDIT PERFORMANCE\n"
        "4) MACRO & CONSUMER HEALTH\n"
        "5) NEW PRODUCTS, PARTNERSHIPS, OR TECHNOLOGY\n"
        "6) CUTTING-EDGE OR NOTEWORTHY ITEMS (EXPERIMENTAL, DIFFERENTIATED)\n"
        "7) RISKS & WATCH-OUTS\n"
        "8) TACTICAL RESPONSES WE SHOULD CONSIDER AS A COMPETITOR\n"
        "9) ANALYST Q&A SYNTHESIS (synthesis of questions analysts asked and answers given, keeping an eye out for themes in questions)\n\n"
        "Emphasize details critical to a rival fintech CEO: pricing shifts, channel moves, capital or liquidity signals,\n"
        "operational changes, regulatory posture, and any data that hints at momentum or weakness.\n\n"
        f"Transcript:\n\"\"\"{transcript_block}\"\"\"\n"
    )


def synthesize_transcript(
    transcript_path: Path | str,
    *,
    company: str,
    model: str = "gpt-4.1",
    client: Optional[OpenAI] = None,
    max_output_tokens: int = 16000,
    extra_instructions: Optional[Iterable[str]] = None,
    transcript_text_override: Optional[str] = None,
) -> TranscriptSummary:
    """Read a transcript file and return a synthesized summary.

    Args:
        transcript_path: Path to the plain-text earnings call transcript.
        company: Name of the company whose transcript is being summarized.
        model: OpenAI chat model identifier to use.
        client: Optional shared OpenAI client. If not provided, a new client is created
            using environment configuration.
        max_output_tokens: Upper bound for tokens in the generated summary.
        extra_instructions: Optional list of bullet instructions appended to the
            system message for caller-specific guidance.
        transcript_text_override: Raw transcript content to use instead of reading from disk.

    Returns:
        TranscriptSummary containing the synthesized content.
    """

    path = Path(transcript_path)
    if not transcript_text_override and not path.exists():
        raise FileNotFoundError(f"Transcript file not found: {path}")

    transcript = transcript_text_override or path.read_text(encoding="utf-8")
    if not transcript.strip():
        raise ValueError("Transcript content is empty; provide text to summarize.")

    guidance_lines = list(extra_instructions or [])
    guidance = "\n".join(f"- {line}" for line in guidance_lines)
    system_prompt = SYSTEM_PROMPT + (f"\nCaller notes:\n{guidance}" if guidance else "")

    message = _build_user_prompt(company, transcript)

    api_client = client or OpenAI()
    response = api_client.chat.completions.create(
        model=model,
        temperature=0.2,
        max_tokens=max_output_tokens,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message},
        ],
    )

    staging_dir = Path("summary_staging")
    staging_dir.mkdir(parents=True, exist_ok=True)
    staging_path = staging_dir / f"{path.stem}_summary_response.txt"
    staging_path.write_text(response.model_dump_json(indent=2), encoding="utf-8")

    summary_text = response.choices[0].message.content or ""

    return TranscriptSummary(company=company, transcript_path=path, summary_text=summary_text)


def summarize_text(
    transcript: str,
    *,
    company: str,
    model: str = "gpt-4.1",
    client: Optional[OpenAI] = None,
    max_output_tokens: int = 16000,
    extra_instructions: Optional[Iterable[str]] = None,
) -> str:
    """Summarize a transcript string without reading from disk.

    Returns only the summary text and is useful for testing.
    """

    summary = synthesize_transcript(
        Path("in-memory-transcript.txt"),
        company=company,
        model=model,
        client=client,
        max_output_tokens=max_output_tokens,
        extra_instructions=extra_instructions,
        transcript_text_override=transcript,
    )
    return summary.summary_text
