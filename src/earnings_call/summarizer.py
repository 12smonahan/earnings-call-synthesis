"""Generate structured summaries from earnings call transcripts using OpenAI."""

from __future__ import annotations

from collections import OrderedDict
from dataclasses import dataclass
import json
from pathlib import Path
from typing import Iterable, Optional

from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables from .env file if it exists
load_dotenv()


@dataclass
class TranscriptSummary:
    """Container for a synthesized earnings call summary.

    Attributes:
        company: Name of the company covered in the transcript.
        transcript_path: Path to the transcript file that was summarized.
        summary_text: Human-readable summary generated by the language model.
    """

    company: str
    transcript_path: Path
    summary_text: str


SYSTEM_PROMPT = """You are a chief executive at a consumer lending competitor dissecting an earnings call transcript.
Your goal is to extract granular signals that inform strategy, product bets, and competitive positioning.
Write with the urgency and specificity of a CEO preparing a counter-move playbook. Avoid corporate euphemisms; favor concrete, quotable facts.
Pay particular attention to details that may indicate changing health of the US consumer, the trajectory of this companay, and any key competitive intelligence (underwriting changes, new product features, etc.)
"""

@dataclass
class SectionPrompt:
    """Structured instruction for a focused model call."""

    title: str
    instruction: str
    prompt_label: str | None = None


SECTION_PROMPTS: list[SectionPrompt] = [
    SectionPrompt(
        title="EXECUTIVE SUMMARY",
        prompt_label="PART 1",
        instruction=(
            "Draft the first half of the executive summary (175-225 words) centered on competitive implications, pricing/credit signals, capital/liquidity posture, and channel moves."
            " Be decisive, include specific metrics, and avoid filler so that a rival CEO can act."
        ),
    ),
    SectionPrompt(
        title="EXECUTIVE SUMMARY",
        prompt_label="PART 2",
        instruction=(
            "Continue the executive summary with new evidence and implications (175-225 words) without repeating part 1."
            " Emphasize directional changes, quantified results, and product/capability references that sharpen the threat picture."
        ),
    ),
    SectionPrompt(
        title="ECONOMIC PERFORMANCE",
        instruction=(
            "Explain revenue, margins, unit economics, and cost trends using specific levels and directionality."
            " Anchor on changes versus last quarter/year with supporting metrics and connect to strategic questions in 2-3 paragraphs."
        ),
    ),
    SectionPrompt(
        title="CREDIT PERFORMANCE",
        instruction=(
            "Cover losses, delinquency, reserves, and underwriting shifts with directional changes and trade-offs."
            " Provide a dense 2-3 paragraph synthesis that answers the main credit health question."
        ),
    ),
    SectionPrompt(
        title="MACRO & CONSUMER HEALTH",
        instruction=(
            "Describe demand signals, spending patterns, borrower stress indicators, and any macro commentary."
            " Connect to consumer strength/weakness in 2-3 paragraphs framed around the sharpest question raised by the call."
        ),
    ),
    SectionPrompt(
        title="NEW PRODUCTS, PARTNERSHIPS, OR TECHNOLOGY",
        instruction=(
            "Identify launches, pilots, partnerships, distribution changes, and tech investments."
            " Summarize the implications in 2-3 paragraphs by answering the most urgent competitive question about these moves."
        ),
    ),
    SectionPrompt(
        title="CUTTING-EDGE OR NOTEWORTHY ITEMS (EXPERIMENTAL, DIFFERENTIATED)",
        instruction=(
            "Call out experimental ideas, differentiated capabilities, or unusual tactics."
            " Deliver 2-3 paragraphs answering the key question: what here could shift the playing field?"
        ),
    ),
    SectionPrompt(
        title="RISKS & WATCH-OUTS",
        instruction=(
            "List emerging risks (regulatory, liquidity, operational, reputation) and explain why they matter now."
            " Use 2-3 paragraphs tied to the critical risk question for a competitor."
        ),
    ),
    SectionPrompt(
        title="TACTICAL RESPONSES WE SHOULD CONSIDER AS A COMPETITOR",
        instruction=(
            "Recommend concrete counter-moves, pricing/credit responses, or channel plays we should make."
            " Provide 2-3 paragraphs that directly answer what we must do next and why."
        ),
    ),
    SectionPrompt(
        title="ANALYST Q&A SYNTHESIS",
        instruction=(
            "Summarize analyst questions and management answers, focusing on themes and what they reveal."
            " Provide 2-3 paragraphs that answer the key question revealed by Q&A themes."
        ),
    ),
]


def _build_user_prompt(company: str, transcript: str) -> str:
    """Create the instruction prompt for the model.

    The prompt asks for a competitor-focused readout that captures:
    * Economic performance and revenue/expense trends.
    * Credit performance and underwriting details (losses, delinquencies, reserves).
    * Commentary on macro conditions and consumer health.
    * New products, partnerships, and channel/tech updates.
    * Any cutting-edge ideas or signals that warrant extra attention.
    * Brief risks and watch-outs.
    """

    transcript_block = transcript.strip()
    return (
        f"You are reviewing the {company} earnings call transcript.\n"
        "Summarize for a consumer lending competitor CEO preparing a counter-strategy.\n"
        "Deliver 2,500-3,000 words total with a ~350 word executive summary followed by multi-paragraph deep dives for every section.\n"
        "Use explicit metrics (levels and directionality), cite product names, and call out signals that demand a response.\n"
        "Keep prose direct and decisive, but format as plain text (no Markdown or bullet symbols).\n"
        "For readability in email, use uppercase section headers, short paragraphs, and divider lines made of '=' characters between major sections.\n"
        "Do not truncate sectionsâ€”ensure each requested area is fully covered even if the response is lengthy, and keep writing until every deep dive is complete.\n\n"
        "Required structure:\n"
        "1) EXECUTIVE SUMMARY (~300 words focused on competitive implications)\n"
        "2) ECONOMIC PERFORMANCE\n"
        "3) CREDIT PERFORMANCE\n"
        "4) MACRO & CONSUMER HEALTH\n"
        "5) NEW PRODUCTS, PARTNERSHIPS, OR TECHNOLOGY\n"
        "6) CUTTING-EDGE OR NOTEWORTHY ITEMS (EXPERIMENTAL, DIFFERENTIATED)\n"
        "7) RISKS & WATCH-OUTS\n"
        "8) TACTICAL RESPONSES WE SHOULD CONSIDER AS A COMPETITOR\n"
        "9) ANALYST Q&A SYNTHESIS (synthesis of questions analysts asked and answers given, keeping an eye out for themes in questions)\n\n"
        "Emphasize details critical to a rival fintech CEO: pricing shifts, channel moves, capital or liquidity signals,\n"
        "operational changes, regulatory posture, and any data that hints at momentum or weakness.\n\n"
        f"Transcript:\n\"\"\"{transcript_block}\"\"\"\n"
    )


def _build_section_prompt(
    company: str,
    transcript: str,
    section_title: str,
    section_instruction: str,
    prompt_label: str | None = None,
) -> str:
    """Create a focused prompt for an individual section.

    Each section asks the model to answer the sharpest question raised by that domain
    in 1-3 paragraphs so that responses can be safely stitched together without
    truncation of a monolithic response.
    """

    transcript_block = transcript.strip()
    label_text = f" ({prompt_label})" if prompt_label else ""
    return (
        f"You are reviewing the {company} earnings call transcript.\n"
        f"Focus exclusively on the section '{section_title}'{label_text} and ignore all other headings.\n"
        "Write for a rival fintech CEO preparing a counter-strategy: decisive prose, no bullets, and explicit metrics with directionality.\n"
        "Maintain the overall 2,500-3,000 word target across nine sections; keep this portion dense so the stitched output is complete.\n"
        "Use uppercase section headers, short paragraphs, and avoid Markdown symbols.\n"
        f"Section guidance: {section_instruction}\n\n"
        f"Transcript:\n\"\"\"{transcript_block}\"\"\"\n"
    )


def synthesize_transcript(
    transcript_path: Path | str,
    *,
    company: str,
    model: str = "gpt-4.1",
    client: Optional[OpenAI] = None,
    max_output_tokens: int = 16000,
    extra_instructions: Optional[Iterable[str]] = None,
    transcript_text_override: Optional[str] = None,
    use_sectioned_prompts: bool = False,
) -> TranscriptSummary:
    """Read a transcript file and return a synthesized summary.

    Args:
        transcript_path: Path to the plain-text earnings call transcript.
        company: Name of the company whose transcript is being summarized.
        model: OpenAI chat model identifier to use.
        client: Optional shared OpenAI client. If not provided, a new client is created
            using environment configuration.
        max_output_tokens: Upper bound for tokens in the generated summary. For sectioned
            prompts the per-section cap is derived from this value.
        extra_instructions: Optional list of bullet instructions appended to the
            system message for caller-specific guidance.
        transcript_text_override: Raw transcript content to use instead of reading from disk.
        use_sectioned_prompts: If True, split the request into per-section prompts to avoid
            truncation and stitch the responses together.

    Returns:
        TranscriptSummary containing the synthesized content.
    """

    path = Path(transcript_path)
    if not transcript_text_override and not path.exists():
        raise FileNotFoundError(f"Transcript file not found: {path}")

    transcript = transcript_text_override or path.read_text(encoding="utf-8")
    if not transcript.strip():
        raise ValueError("Transcript content is empty; provide text to summarize.")

    guidance_lines = list(extra_instructions or [])
    guidance = "\n".join(f"- {line}" for line in guidance_lines)
    system_prompt = SYSTEM_PROMPT + (f"\nCaller notes:\n{guidance}" if guidance else "")

    api_client = client or OpenAI()

    staging_dir = Path("summary_staging")
    staging_dir.mkdir(parents=True, exist_ok=True)
    staging_path = staging_dir / f"{path.stem}_summary_response.txt"

    if use_sectioned_prompts:
        per_section_tokens = max(400, max_output_tokens // len(SECTION_PROMPTS))
        stitched_sections: "OrderedDict[str, list[str]]" = OrderedDict()
        staged_responses: list[dict[str, object]] = []

        for idx, section_prompt in enumerate(SECTION_PROMPTS, start=1):
            message = _build_section_prompt(
                company,
                transcript,
                section_prompt.title,
                section_prompt.instruction,
                prompt_label=section_prompt.prompt_label,
            )
            response = api_client.chat.completions.create(
                model=model,
                temperature=0.2,
                max_tokens=per_section_tokens,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message},
                ],
            )
            raw_content = response.choices[0].message.content
            if isinstance(raw_content, list):
                section_body = "".join(
                    part.get("text", "") if isinstance(part, dict) else getattr(part, "text", "")
                    for part in raw_content
                )
            else:
                section_body = raw_content or ""

            stitched_sections.setdefault(section_prompt.title, []).append(section_body.strip())
            staged_responses.append(
                {
                    "index": idx,
                    "title": section_prompt.title,
                    "prompt_label": section_prompt.prompt_label,
                    "request": message,
                    "response": response.model_dump(),
                }
            )

        formatted_sections: list[str] = []
        for display_index, (title, paragraphs) in enumerate(stitched_sections.items(), start=1):
            paragraph_block = "\n\n".join(filter(None, paragraphs))
            formatted_sections.append(
                f"{display_index}) {title}\n"
                f"{'=' * 80}\n"
                f"{paragraph_block}\n"
            )

        summary_text = "\n\n".join(formatted_sections)
        staging_path.write_text(json.dumps(staged_responses, indent=2), encoding="utf-8")
    else:
        message = _build_user_prompt(company, transcript)
        response = api_client.chat.completions.create(
            model=model,
            temperature=0.2,
            max_tokens=max_output_tokens,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message},
            ],
        )
        staging_path.write_text(response.model_dump_json(indent=2), encoding="utf-8")

        raw_content = response.choices[0].message.content
        if isinstance(raw_content, list):
            summary_text = "".join(
                part.get("text", "") if isinstance(part, dict) else getattr(part, "text", "")
                for part in raw_content
            )
        else:
            summary_text = raw_content or ""

    return TranscriptSummary(company=company, transcript_path=path, summary_text=summary_text)


def summarize_text(
    transcript: str,
    *,
    company: str,
    model: str = "gpt-4.1",
    client: Optional[OpenAI] = None,
    max_output_tokens: int = 16000,
    extra_instructions: Optional[Iterable[str]] = None,
    use_sectioned_prompts: bool = False,
) -> str:
    """Summarize a transcript string without reading from disk.

    Returns only the summary text and is useful for testing.
    """

    summary = synthesize_transcript(
        Path("in-memory-transcript.txt"),
        company=company,
        model=model,
        client=client,
        max_output_tokens=max_output_tokens,
        extra_instructions=extra_instructions,
        transcript_text_override=transcript,
        use_sectioned_prompts=use_sectioned_prompts,
    )
    return summary.summary_text
